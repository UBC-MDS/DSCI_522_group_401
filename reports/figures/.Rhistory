result <- freq(data)
test_that("Input data should not be null!!",{
expect_gt(str_length(data), 0)
})
print("Success!!")
```
Trying with an empty data
```{r, error=TRUE}
data <- ""
result <- freq(data)
test_that("Input data should not be null!!",{
expect_gt(str_length(data), 0)
})
print("Success!!")
```
install.packages(c("rlang", "stringdist"))
View(iris)
library(dplyr)
library(tidyverse)
purr_df <- nycflights13::weather %>%
select(origin, month, temp) %>%
group_by(origin, month)%>%
nest()
library(dplyr)
library(tidyverse)
library(repr)
purr_df <- nycflights13::weather %>%
select(origin, month, temp) %>%
group_by(origin, month)%>%
nest()
purr_df
purr_df$data
?min
a <- "ASIA_AUSTRALIA"
str_split(a,"_")
library(tidyverse)
str_split(a,pattern = "_")
str_split(a,pattern = "_")[[1]]
str_split(a,pattern = "_")[[1]][1]
str_split(a,pattern = "_")[[1]][2]
"a" <"b"
"a" >"b"
library(dplyr)
download.file(url = "https://raw.github.ubc.ca/MDS-2019-20/DSCI_531_viz-1_students/master/datasets/us_contagious_diseases.csv?token=AAAHXRY78jsgJ673VF9t98KwwKLQxdycks5dwKD8wA%3D%3D", destfile = "/Users/karan/Documents/UBC MDS/Labs/Block 2/DSCI 531/DSCI_531_lab3_ksingh20/us_contagious_diseases.csv")
install.packages("rgdal")
install.packages("rgeos")
require(rgeos)
install.packages("rgdal")
library(digest)
library(testthat)
library(tidyverse)
library(infer)
library(repr)
library(gridExtra)
library(forcats)
library(broom)
?rnorm
?geom_hline
?dist
?rnorm
?rbinom
rbinom(2, size = 1, prob = 0.7)
rbinom(4, size = 1, prob = 0.7)
arr = c[1,2,3]
arr = c(1,2,3)
arr[1]
arr[length(arr)]
install.packages(c("geojsonio", "hms", "rgdal"))
library(tidyr)
table4a
gather(table4a, key = year, value = -country)
gather(table4a, key = year, value = cases, -country)
library(tidyverse)
unicef_df <- read_csv("https://sejdemyr.github.io/r-tutorials/basics/data/unicef-u5mr.csv")
gather(unicef_df, key = year, value = cases, -countryName)
gather(unicef_df, key = year, value = cases, -countryname)
gather(unicef_df, key = year, value = cases, -CountryName)
df <- gather(unicef_df, key = year, value = cases, -CountryName)
mutate(df, year = sub("U5MR","",year))
mutate(df, year = as.numeric(sub("U5MR","",year)))
table2
spread(table2, key = type, value = count)
library(tibble)
# making a tibble using the tribble function
weather_df <- tribble(
~id,       ~date,      ~element, ~temp,
"MX17004", "2010-01-30", "tmax", 27.8,
"MX17004", "2010-01-30", "tmin", 14.5,
"MX17004", "2010-02-02", "tmax", 27.3,
"MX17004", "2010-02-02", "tmin", 14.4,
"MX17004", "2010-02-03", "tmax", 24.1,
"MX17004", "2010-02-03", "tmin", 14.4,
"MX17004", "2010-02-11", "tmax", 29.7,
"MX17004", "2010-02-11", "tmin", 13.4,
"MX17004", "2010-02-23", "tmax", 29.9,
"MX17004", "2010-02-23", "tmin", 10.7)
weather_df
spread(weather_df, key = element, value = temp)
fruit
# split on " "
str_split(my_fruit, " ")
# split on " "
str_split(fruit, " ")
str_c(fruit[1:4], fruit[5:8], sep = "")
str_c(fruit[1:4], fruit[5:8], sep = "-")
str_c(fruit[1:4], fruit[5:8], sep = " ")
library(gapminder)
# detect countries that start with "AL"
gapminder %>%
filter(str_detect(country, "^Al")) %>%
pull(country) %>%
unique() %>%
length()
# detect countries that start with "AL"
gapminder %>%
filter(str_detect(country, "^Al")) %>%
pull(country)
# detect countries that contain ", Dem. Rep."
gapminder %>%
filter(str_detect(country, "\\, Dem. Rep."))
sentences
# extract nouns from sentences
noun <- "(a|the) ([^ ]+)"
str_match(sentences, noun) %>%
head()
str_sub(fruit, 1,3)
str_sub(fruit, 1,3) <- "AAA"
str_sub(fruit, 1,3)
one_country <- gapminder %>%
select(country, continent) %>%
group_by(country) %>%
slice(1)
head(one_country)
?slice
gapminder %>%
+     select(country, continent) %>%
+     group_by(country) %>%
+     slice(1)
gapminder %>%
+     select(country, continent) %>%
+     group_by(country) %>%
+     slice(1)
gapminder %>%
select(country, continent) %>%
group_by(country)
gapminder %>%
select(country, continent) %>%
group_by(country) %>% slice(1)
gapminder %>%
select(country, continent) %>%
group_by(country) %>% slice(1:2)
gapminder %>%
select(country, continent) %>%
group_by(country) %>% slice(5:10)
t <- as.tibble(mtcars)
t <- as_tibble(mtcars)
class(t)
is.data.frame(t)
is_tibble(t)
is.tibble(t)
mtcars$mpg
pull(mtcars, hp)
class(pull(mtcars, hp))
typeof(pull(mtcars, hp))
set2 <- tribble(
~ country,    ~ group, ~ cases,
"Australia",   "male_young",     1,
"New Zealand",  "male_young",     5,
"Australia",    "male_old",     2,
"New Zealand",  "male_old",    6,
"Australia",     "female_young",     3,
"New Zealand",  "female_young",     7,
"Australia",   "female_old",     4,
"New Zealand",  "female_old",     8)
set2
set2 %>% separate(group, sep = "-")
set2 %>% separate(group, sep = "-", into = c("male","female"))
set2 %>% separate(group, sep = "_", into = c("male","female"))
install.packages(c("rgdal", "tinytex"))
install.packages("rgdal")
install.packages("rgdal")
install.packages("rgdal")
a <- c("sampling, handling")
library(tidyr)
library(tidyverse)
str_subset(a, "\\.*(ing).*")
str_subset(a, "\\.*(ing).*")
a <- c("sampling, handling", "apple", "banana")
str_subset(a, "\\.*(ing).*")
library(tidyverse)
library(gapminder)
gapminder %>%
mutate(gapminder, gdp_total = pop * gdpPercap)
gapminder %>%
mutate(gapminder, gdp_total = pop * gdpPercap)
gapminder %>%
mutate(gdp_total = pop * gdpPercap)
head(gapminder)
gapminder %>% remove(year)
gapminder %>% remove(.,year)
remove(gapminder, year)
gapminder %>% mutate(year = NULL)
head(gapminder %>% mutate(year = NULL))
read_csv("/Users/karan/Desktop/test.csv", skip = 2)
read_csv("/Users/karan/Desktop/test.csv", skip = 1)
read_csv("/Users/karan/Desktop/test.csv", skip = 1, col_names = TRUE)
read_csv("/Users/karan/Desktop/test.csv", skip = 2, col_names = TRUE)
read_csv("/Users/karan/Desktop/test.csv", skip = 3, col_names = TRUE)
read_csv("/Users/karan/Desktop/test.csv", skip = 2, col_names = TRUE)
read_csv("/Users/karan/Desktop/test.csv", skip = 1, col_names = TRUE)
read_csv("/Users/karan/Desktop/test.csv", skip = 1, col_names = TRUE, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 2, col_names = TRUE, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 2, col_names = TRUE, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 2, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 1, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 2, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 1, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 1, n_max = 6, col_names = TRUE)
gapminder
gapminder %>% group_by(country, year) %>% summarise(min_life_exp = min(lifeExp))
gapminder %>% group_by(year) %>% summarise(min_life_exp = min(lifeExp))
read_csv("/Users/karan/Desktop/test.csv", skip = 1, n_max = 6)
read_csv("/Users/karan/Desktop/test.csv", skip = 1, n_max = 6, col_names = TRUE)
download.file(url = "https://raw.github.ubc.ca/MDS-2019-20/datasets/master/data/facebook-links.txt?token=AAAHXWYuvV-9xOOQrt0tTycBEAcaX9qeks5dxOROwA%3D%3D", destfile = "/Users/karan/Desktop/facebook-links.txt")
?qnorm
qnorm("2.5")
qnorm(0.025)
t(x = 2)
?t
require(graphics)
?dt
?qt
dt(0.025)
dt(0.025, df = 1)
dt(0.025, df = 71)
?t.test()
?ifelse
?quantile
library(tidyverse)
library(infer)
?calculate
?specify
?get_pvalue
install.packages("testthat")
data = c(0.8, 2.1, 2.4)
prod(dexp(data,0.5))
prod(dexp(data,0.05))
download.file(url = "https://raw.githubusercontent.com/STAT545-UBC/STAT545-UBC.github.io/master/gapminderDataFiveYear_dirty.txt", destfile = "/Users/karan/Desktop/uncleaned_gapminder.txt")
download.file(url = "https://raw.githubusercontent.com/STAT545-UBC/STAT545-UBC.github.io/master/gapminderDataFiveYear.txt", destfile = "/Users/karan/Desktop/clean_gapminder.txt")
df_1 = read.csv("/Users/karan/Desktop/temp/uncl.csv", sep =",")
View(df_1)
df_2 = read.csv("/Users/karan/Desktop/clean_gapminder.txt", sep = "\t")
View(df_2)
library(testthat)
test_that("test", {})
test_that("test", {})
test_that("test", {expect_equal(df_1,df_2)})
levels(df_1$continent)
?dnorm
?rep
?rep(0,5)
rep(0,5)
rep(0,15)
set.seed(2018)
sample = data.frame(obs = round(rnorm(mean = 10, sd = 1, n = 15), 2))
p_likelihood <- ggplot(data = sample, aes(x = obs, y = rep(0, 15))) +
geom_point(alpha = 0.4, color = "blue") +
xlim(5, 15)
p_likelihood
sample = data.frame(obs = round(rnorm(mean = 10, sd = 1, n = 15), 2))
ggplot(data = sample, aes(x = obs, y = rep(0, 15))) +
geom_point(alpha = 0.4, color = "blue") +
xlim(5, 15)
library(ggplot2)
ggplot(data = sample, aes(x = obs, y = rep(0, 15))) +
geom_point(alpha = 0.4, color = "blue") +
xlim(5, 15)
sample
?dnorm
pos
?pos
?pois
?rpoin
?rpois
?dexp
?rexp
rpois(lambda = 2)
rpois(n = 2, lambda = 2)
exp(-2)
exp(-1)
# set seed
set.seed(2019)
# create sample space
outcomes <- c("complication", "no complication")
# draw the first sample of size 62 from the null distribution
sim1 <- sample(outcomes, size = 62, prob = c(0.1, 0.9), replace = TRUE)
# view the sample
table(sim1)
# calculate the simulated sample proportion of complications (red chips)
(p_hat_sim1 <- sum(sim1 == "complication") / length(sim1))
im_dist <- data.frame(p_hat_sim = rep(NA, 3))
im_dist
im_dist$p_hat_sim[1] <- p_hat_sim1
im_dist
0.0484988452655889-0.0284770945109369
?prop.test
iris
df <- iris
cor(df$Sepal.Length, df$Sepal.Width)
cor(df$Petal.Length,df$Petal.Width)
install.packages(c("covr", "digest", "DT", "e1071", "haven", "igraph", "infer", "knitr", "maptools", "Matrix", "mgcv", "nlme", "quadprog", "R6", "Rcpp", "rgdal", "rlang", "rmarkdown", "roxygen2", "rvest", "scales", "selectr", "sp", "survival", "testthat", "tidyverse", "webshot", "xfun"))
install.packages(c("curl", "roxygen2", "rversions", "survival", "testthat"))
library(devtools)
install_github('plotly/dashR')
install.packages(c("forecast", "IRkernel", "listenv", "reqres", "roxygen2", "survival"))
install.packages(c("forecast", "globals", "RcppArmadillo"))
install.packages("tictoc")
install.packages(c("callr", "cli", "data.table", "fracdiff", "nlme", "plyr"))
install.packages("rnaturalearth")
install.packages("rnaturalearthdata")
install.packages("viridis")
install.packages("plotly")
install.packages("maps")
Sys.setenv("plotly_username"="ksingh20")
Sys.setenv("plotly_api_key"="769qqo8YdHscRLmp4P8B")
library(tidyverse, quiet = True)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggplot2)
library(viridis)
library(maps)
library(plotly)
library(dash)
library(dashCoreComponents)
library(dashHtmlComponents)
app <- Dash$new(external_stylesheets = "https://codepen.io/chriddyp/pen/bWLwgP.css")
# Wrangling with world map data
earthquake_data <- read_csv("/Users/karan/Desktop/data/earthquake_data.csv") %>%
rename(region = Country) %>%
mutate(region = ifelse(region == "United States", "USA", region))
worldmap <- map_data('world')
earthquake_data <- left_join(earthquake_data, worldmap, by = "region") %>%
select(-subregion, -order)
# Set up a plain theme for world map
plain <- theme(
axis.text = element_blank(),
axis.line = element_blank(),
axis.ticks = element_blank(),
panel.grid = element_blank(),
axis.title = element_blank(),
panel.background = element_rect(fill = "lightblue"),
plot.title = element_text(hjust = 0.5),
legend.position = "none"
)
# Drawing the map using ggplot2
p <- ggplot(data = earthquake_data, aes(long, lat, group = group, frame = Year,
text = paste("Country: ", region, "\n",
"# Deaths: ", Death_earthquake))) +
coord_fixed(1.3) +
geom_polygon(aes(fill = Death_rate), color = "darkblue", size = 0.15) +
scale_fill_viridis_c(option = "magma", direction = -1, trans = "log") +
labs(title = "World Map of Annual Death Rate") +
plain
# Add ggplotly animations to the plot to reflect selected year changes
p <- ggplotly(p, tooltip = c('text', 'frame')) %>%
animation_opts(transition = 0.01, easing = "linear", redraw = TRUE, mode = "immediate")
api_create(p, filename = "world_map")
api_create(p, filename = "world_map")
object.size(p)
54464792/1024
53188.27/1024
nrow(earthquake_data)
object.size(earthquake_data)/1024
140197.7/1024
View(earthquake_data)
nrow(earthquake_data)
library(tidyverse)
library(broom)
library(rsample)
gpa_data <- read_csv("gpa_data.csv")
brain_data <- read_csv("brain_data.csv")
marathon <- read_csv("marathon.csv", col_types = cols(
id = col_factor(),
female = col_factor(),
footwear = col_factor(),
group = col_factor(),
injury = col_factor()
)) %>%
filter(completed_marathon == 1) %>%
mutate(speed = distance / time,
id = factor(id),) %>%
select(-c(completed_marathon,
distance,
time))
head(iris)
model <- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)
tidy(model)
model <- lm(Sepal.Width ~ Sepal.Length * Species, data = iris)
tidy(model, conf.int = TRUE)
iris
iris %>% filter(Sepal.Length == 5.0 & Species == 'setosa')
newdata <- iris %>% filter(Sepal.Length == 5.0 & Species == 'setosa') %>% select(Sepal.Length, Species)
predict(newdata, interval = "confidence")
newdata <- iris %>% filter(Sepal.Length == 5.0 & Species == 'setosa') %>% select(Sepal.Length, Species)
newdata
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa') %>%
select(Sepal.Length, Species)
newdata
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa') %>%
select(Sepal.Length, Species)
predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa') %>%
select(Sepal.Length, Species)
newdata
#predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa') %>%
select(Sepal.Length, Species)
predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa') %>%
select(Sepal.Length, Species)
nrow(newdata)
predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa')
nrow(newdata)
predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa')
nrow(newdata)
predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa')
nrow(newdata)
predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa')
newdata
predict(object = model, newdata = newdata, interval = "confidence")
newdata <- iris %>%
filter(Sepal.Length == 5.0 & Species == 'setosa')
predict(object = model, newdata = newdata, interval = "confidence")
predict(object = model, newdata = newdata, interval = "prediction")
model_add <- lm(univ_gpa ~ high_gpa + math_sat + verb_sat, data = gpa_data)
gpa_data
gpa_data[-4]
ggplot(gpa_data[-4]) + geom_tile()
ggplot(gpa_data[-4], aes(.)) + geom_tile()
ggplot(gpa_data[-4], aes(high_gpa, math_sat)) + geom_tile()
ggplot(gpa_data[-4], aes(high_gpa, math_sat,verb_sat)) + geom_tile()
#ggplot(gpa_data[-4], aes(high_gpa, math_sat,verb_sat)) + geom_tile()
corr(gpa_data)
#ggplot(gpa_data[-4], aes(high_gpa, math_sat,verb_sat)) + geom_tile()
cor(gpa_data)
ggplot(cor(gpa_data[-4])) + geom_tile()
#ggplot(cor(gpa_data[-4]), aes()) + geom_tile()
melt(cor(gpa_data))
#ggplot(cor(gpa_data[-4]), aes()) + geom_tile()
library(reshape)
melt(cor(gpa_data))
library(tidyverse)
library(broom)
library(rsample)
library(reshape)
#ggplot(cor(gpa_data[-4]), aes()) + geom_tile()
melt(cor(gpa_data[-4]))
ggplot(melt(cor(gpa_data[-4])), aes(X1,X2)) + geom_tile()
#melt(cor(gpa_data[-4]))
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels =     rev(sort(unique(X2)))))) + geom_tile(aes(fill = value))
#melt(cor(gpa_data[-4]))
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels =     rev(sort(unique(X2)))))) + geom_tile(aes(fill = value))
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) + geom_tile(aes(fill = value))
cor(gpa_data[-4])
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) + geom_tile(aes(fill = value))
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) + geom_tile(aes(fill = value)) +labs(x = "")
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) + geom_tile(aes(fill = value)) +labs(x = "", y = "", title = "Correlation")
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) + geom_tile(aes(fill = value)) +labs(x = "", y = "", title = "Correlation Matrix")
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) +
geom_tile(aes(fill = value)) +
labs(x = "", y = "", title = "Correlation Matrix")
cor(gpa_data[-4])
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) +
geom_tile(aes(fill = value)) +
labs(x = "", y = "", title = "Correlation Matrix")
ggplot(melt(cor(gpa_data[-4])), aes(X1, ordered(X2, levels = rev(sort(unique(X2)))))) +
geom_tile(aes(fill = value)) +
labs(x = "", y = "", title = "Correlation Matrix")
install.packages("car")
library(tidyverse)
library(broom)
library(rsample)
library(reshape)
library(car)
vif(model_add)
model_add_test <- lm(univ_gpa ~ math_sat + verb_sat + high_gpa , data = gpa_data)
vif(model_add_test)
model_add_test <- lm(univ_gpa ~ math_sat + verb_sat + high_gpa , data = gpa_data)
vif(model_add_test)
install.packages("reticulate")
library(reticulate)
install.packages(c("BH", "boot", "broom", "car", "cli", "DBI", "DT", "fansi", "foreign", "hms", "MASS", "mime", "pillar", "plyr", "prettyunits", "quantreg", "repr", "reticulate", "rmarkdown", "SparseM", "stringi", "tinytex", "TTR", "V8", "vctrs", "zoo"))
install.packages(c("stringi", "V8", "zoo"))
install.packages("docopt")
pwd
getwd
setwd('/Users/karan/Documents/UBC MDS/Labs/Block 4/DSCI 522/Milestone 2/DSCI_522_group_401/reports/figures/')
getwd
getwd()
